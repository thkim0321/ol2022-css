{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: For loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `obama-trump.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"obama-trump.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Print first 5 elements in data[0] using for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @PlaysTrumpCard: @realDonaldTrump We support you because we know your heart is in the right place, and greatly appreciate what an incred…\n",
      "Don't let the facts get drowned out. Join the OFA Truth Team today: https://t.co/RgBRNLYdYl https://t.co/SN8HUXw2H4\n",
      "Judge Merrick Garland just received the American Bar Association's highest rating: https://t.co/9ew2WSpFqd\n",
      "Proud to cheer on Team USA at the Invictus Games today with my friend Joe. You represent the best of our country. https://t.co/WBzcltmgqj\n",
      "When someone shares their story, we see the world through their eyes. I’m looking forward to hearing a few from leaders around the world and sharing my own at the @ObamaFoundation Summit in Chicago. Tune in at https://t.co/GYkEOK8EuT. https://t.co/sOllDsDA1Z\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "for i in data[0][0:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \n",
    "### 2-1. Import following libraries:\n",
    "-  `SnowballStemmer` from `nltk.stem.snowball` \n",
    "-  `word_tokenize` from `nltk.tokenize`\n",
    "\n",
    "### 2-2. Write a for loop printing first 5 sentence of data[0] after tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'walking']\n",
      "['RT', '@', 'PlaysTrumpCard', ':', '@', 'realDonaldTrump', 'We', 'support', 'you', 'because', 'we', 'know', 'your', 'heart', 'is', 'in', 'the', 'right', 'place', ',', 'and', 'greatly', 'appreciate', 'what', 'an', 'incred…']\n",
      "['Do', \"n't\", 'let', 'the', 'facts', 'get', 'drowned', 'out', '.', 'Join', 'the', 'OFA', 'Truth', 'Team', 'today', ':', 'https', ':', '//t.co/RgBRNLYdYl', 'https', ':', '//t.co/SN8HUXw2H4']\n",
      "['Judge', 'Merrick', 'Garland', 'just', 'received', 'the', 'American', 'Bar', 'Association', \"'s\", 'highest', 'rating', ':', 'https', ':', '//t.co/9ew2WSpFqd']\n",
      "['Proud', 'to', 'cheer', 'on', 'Team', 'USA', 'at', 'the', 'Invictus', 'Games', 'today', 'with', 'my', 'friend', 'Joe', '.', 'You', 'represent', 'the', 'best', 'of', 'our', 'country', '.', 'https', ':', '//t.co/WBzcltmgqj']\n",
      "['When', 'someone', 'shares', 'their', 'story', ',', 'we', 'see', 'the', 'world', 'through', 'their', 'eyes', '.', 'I', '’', 'm', 'looking', 'forward', 'to', 'hearing', 'a', 'few', 'from', 'leaders', 'around', 'the', 'world', 'and', 'sharing', 'my', 'own', 'at', 'the', '@', 'ObamaFoundation', 'Summit', 'in', 'Chicago', '.', 'Tune', 'in', 'at', 'https', ':', '//t.co/GYkEOK8EuT', '.', 'https', ':', '//t.co/sOllDsDA1Z']\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for i in data[0][0:5]:\n",
    "    print(word_tokenize(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Write a for loop which print first 5 sentence of data[0] after getting each word stemmed (use SnowballStemmer). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt\n",
      "@\n",
      "playstrumpcard\n",
      ":\n",
      "@\n",
      "realdonaldtrump\n",
      "we\n",
      "support\n",
      "you\n",
      "becaus\n",
      "we\n",
      "know\n",
      "your\n",
      "heart\n",
      "is\n",
      "in\n",
      "the\n",
      "right\n",
      "place\n",
      ",\n",
      "and\n",
      "great\n",
      "appreci\n",
      "what\n",
      "an\n",
      "incred…\n",
      "do\n",
      "n't\n",
      "let\n",
      "the\n",
      "fact\n",
      "get\n",
      "drown\n",
      "out\n",
      ".\n",
      "join\n",
      "the\n",
      "ofa\n",
      "truth\n",
      "team\n",
      "today\n",
      ":\n",
      "https\n",
      ":\n",
      "//t.co/rgbrnlydyl\n",
      "https\n",
      ":\n",
      "//t.co/sn8huxw2h4\n",
      "judg\n",
      "merrick\n",
      "garland\n",
      "just\n",
      "receiv\n",
      "the\n",
      "american\n",
      "bar\n",
      "associ\n",
      "'s\n",
      "highest\n",
      "rate\n",
      ":\n",
      "https\n",
      ":\n",
      "//t.co/9ew2wspfqd\n",
      "proud\n",
      "to\n",
      "cheer\n",
      "on\n",
      "team\n",
      "usa\n",
      "at\n",
      "the\n",
      "invictus\n",
      "game\n",
      "today\n",
      "with\n",
      "my\n",
      "friend\n",
      "joe\n",
      ".\n",
      "you\n",
      "repres\n",
      "the\n",
      "best\n",
      "of\n",
      "our\n",
      "countri\n",
      ".\n",
      "https\n",
      ":\n",
      "//t.co/wbzcltmgqj\n",
      "when\n",
      "someon\n",
      "share\n",
      "their\n",
      "stori\n",
      ",\n",
      "we\n",
      "see\n",
      "the\n",
      "world\n",
      "through\n",
      "their\n",
      "eye\n",
      ".\n",
      "i\n",
      "’\n",
      "m\n",
      "look\n",
      "forward\n",
      "to\n",
      "hear\n",
      "a\n",
      "few\n",
      "from\n",
      "leader\n",
      "around\n",
      "the\n",
      "world\n",
      "and\n",
      "share\n",
      "my\n",
      "own\n",
      "at\n",
      "the\n",
      "@\n",
      "obamafound\n",
      "summit\n",
      "in\n",
      "chicago\n",
      ".\n",
      "tune\n",
      "in\n",
      "at\n",
      "https\n",
      ":\n",
      "//t.co/gykeok8eut\n",
      ".\n",
      "https\n",
      ":\n",
      "//t.co/solldsda1z\n"
     ]
    }
   ],
   "source": [
    "# Your cod\n",
    "for i in data[0][0:5]:\n",
    "    for w in word_tokenize(i):\n",
    "        print(SnowballStemmer('english').stem(w))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a function that..\n",
    "- receive a sentence (as an argument)\n",
    "- print words after stemming (use SnowballStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "like\n",
      "walk\n",
      "with\n",
      "my\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "def printStemmedWords(sentence):\n",
    "    for word in word_tokenize(sentence, \"english\"):\n",
    "        stemmedWord = SnowballStemmer(\"english\").stem(word)\n",
    "        print(stemmedWord)\n",
    "\n",
    "printStemmedWords(\"I like walking with my dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Taehee']\n",
      "['Taehee', 'Mona']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TaeheeMona'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_list = []\n",
    "print(empty_list)\n",
    "empty_list.append(\"Taehee\")\n",
    "print(empty_list)\n",
    "empty_list.append(\"Mona\")\n",
    "print(empty_list)\n",
    "\" \".join(empty_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
